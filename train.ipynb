{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Prepare Data With Only One Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport csv\\nimport cv2\\nimport numpy as np\\nfrom PIL import Image\\n\\nlines = []\\nwith open('data/driving_log.csv') as csvfile:\\n    reader = csv.reader(csvfile)\\n    for line in reader:\\n        lines.append(line)\\n\\nimages = []\\nmeasurements = []\\nheader = True\\n\\nfor line in lines:\\n    if header:\\n        header = False\\n        continue\\n    \\n    source_path = line[0]\\n    file_name = source_path.split('/')[-1]\\n    current_path = 'data/IMG/' + file_name\\n    #image = cv2.imread(current_path)\\n    image = np.asarray(Image.open(current_path))\\n    images.append(image)\\n    measurement = float(line[3])\\n    measurements.append(measurement)\\n    \\n    # augmenting data\\n    image_flipped = np.fliplr(image)\\n    images.append(image_flipped)\\n    measurement_flipped = -measurement\\n    measurements.append(measurement_flipped)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "lines = []\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "images = []\n",
    "measurements = []\n",
    "header = True\n",
    "\n",
    "for line in lines:\n",
    "    if header:\n",
    "        header = False\n",
    "        continue\n",
    "    \n",
    "    source_path = line[0]\n",
    "    file_name = source_path.split('/')[-1]\n",
    "    current_path = 'data/IMG/' + file_name\n",
    "    #image = cv2.imread(current_path)\n",
    "    image = np.asarray(Image.open(current_path))\n",
    "    images.append(image)\n",
    "    measurement = float(line[3])\n",
    "    measurements.append(measurement)\n",
    "    \n",
    "    # augmenting data\n",
    "    image_flipped = np.fliplr(image)\n",
    "    images.append(image_flipped)\n",
    "    measurement_flipped = -measurement\n",
    "    measurements.append(measurement_flipped)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Prepare Data With All Cameras and Augmented Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "lines = []\n",
    "car_images = []\n",
    "steering_angles = []\n",
    "\n",
    "with open('data/driving_log.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        steering_center = float(row[3])\n",
    "\n",
    "        # create adjusted steering measurements for the side camera images\n",
    "        correction = 0.2 # this is a parameter to tune\n",
    "        steering_left = steering_center + correction\n",
    "        steering_right = steering_center - correction\n",
    "\n",
    "        # read in images from center, left and right cameras\n",
    "        path = \"data/IMG/\" # fill in the path to your training IMG directory\n",
    "        img_center = np.asarray(Image.open(path + row[0].split('\\\\')[-1]))\n",
    "        img_left = np.asarray(Image.open(path + row[1].split('\\\\')[-1]))\n",
    "        img_right = np.asarray(Image.open(path + row[2].split('\\\\')[-1]))\n",
    "\n",
    "        # add images and angles to data set\n",
    "        car_images.extend([img_center, img_left, img_right])\n",
    "        steering_angles.extend([steering_center, steering_left, steering_right])\n",
    "        \n",
    "        # augmenting data: flipping images and steering\n",
    "        img_center_flipped = np.fliplr(img_center)\n",
    "        img_left_flipped = np.fliplr(img_left)\n",
    "        img_right_flipped = np.fliplr(img_right)\n",
    "        car_images.extend([img_center_flipped, img_left_flipped, img_right_flipped])\n",
    "        steering_center_flipped = -steering_center\n",
    "        steering_left_flipped = -steering_left\n",
    "        steering_right_flipped = -steering_right\n",
    "        steering_angles.extend([steering_center_flipped, steering_left_flipped, steering_right_flipped])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(car_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(steering_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#from keras.models import Sequential\n",
    "#from keras.layers import Flatten, Dense, Lambda\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(1))\n",
    "\n",
    "#model.compile(loss='mse', optimizer='adam')\n",
    "#model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=2)\n",
    "\n",
    "#model.save('model/first_20210301.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "4.2.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "\n",
    "from keras.layers import Cropping2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "print(keras.__version__)\n",
    "\n",
    "import socketio\n",
    "print(socketio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d (Cropping2D)      (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 43, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8448)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               844900    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 981,819\n",
      "Trainable params: 981,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The CNN architecture is used from NVIDIA's End to End Learning for Self-Driving Cars paper.\n",
    "Reference: https://arxiv.org/pdf/1604.07316v1.pdf\n",
    "'''\n",
    "#Keras Sequential Model\n",
    "model = Sequential()\n",
    "\n",
    "#Image cropping to get rid of the irrelevant parts of the image (the hood and the sky)\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(160,320,3)))\n",
    "\n",
    "#Pre-Processing the image\n",
    "#model.add(Lambda(preprocess))\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5))\n",
    "\n",
    "#The layers\n",
    "model.add(Conv2D(filters=24, kernel_size=(5, 5), strides=(2, 2),activation='relu'))\n",
    "model.add(Conv2D(filters=36, kernel_size=(5, 5),strides=(2, 2), activation='relu'))\n",
    "model.add(Conv2D(filters=48, kernel_size=(5, 5), strides=(2, 2),activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3) ,activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3),activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=50, activation='relu'))\n",
    "model.add(Dense(units=10, activation='relu'))\n",
    "model.add(Dense(units=1))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32880\n",
      "32880\n",
      "(160, 320, 3)\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "print(len(car_images))\n",
    "print(len(steering_angles))\n",
    "\n",
    "print(car_images[1].shape)\n",
    "print(steering_angles[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "822/822 [==============================] - 418s 496ms/step - loss: 0.0649 - val_loss: 0.0314\n",
      "Epoch 2/10\n",
      "822/822 [==============================] - 245s 298ms/step - loss: 0.0490 - val_loss: 0.0290\n",
      "Epoch 3/10\n",
      "822/822 [==============================] - 245s 298ms/step - loss: 0.0403 - val_loss: 0.0339\n",
      "Epoch 4/10\n",
      "822/822 [==============================] - 244s 297ms/step - loss: 0.0356 - val_loss: 0.0350\n",
      "Epoch 5/10\n",
      "822/822 [==============================] - 248s 302ms/step - loss: 0.0309 - val_loss: 0.0333\n",
      "Epoch 6/10\n",
      "822/822 [==============================] - 249s 303ms/step - loss: 0.0290 - val_loss: 0.0321\n",
      "Epoch 7/10\n",
      "822/822 [==============================] - 247s 301ms/step - loss: 0.0257 - val_loss: 0.0327\n",
      "Epoch 8/10\n",
      "822/822 [==============================] - 248s 302ms/step - loss: 0.0244 - val_loss: 0.0329\n",
      "Epoch 9/10\n",
      "822/822 [==============================] - 251s 305ms/step - loss: 0.0225 - val_loss: 0.0325\n",
      "Epoch 10/10\n",
      "822/822 [==============================] - 247s 300ms/step - loss: 0.0206 - val_loss: 0.0327\n",
      "The model.h5 file has been created!\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=10)\n",
    "\n",
    "model.save('model/first_20210317_10.h5')\n",
    "\n",
    "print('The model.h5 file has been created!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
